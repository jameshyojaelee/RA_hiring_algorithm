---
title: "Test_Py_R"
author: "James Lee"
date: "11/30/2020"
output: html_document
---

```{r}
library(reticulate)
use_python("C:/ProgramData/Anaconda3")
```
 

```{python}
import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn import preprocessing

import requests

filepath = 'C:/Users/james/Desktop/POLI170 Policy memo/RA_hiring_algorithm/RA_dataset.csv'

RA = pd.read_csv(filepath)
print(RA.iloc[:5])

# create subset without categorical values
RA_numeric = RA.drop(['race', 'major'], axis = 1)

# Data normalization is required since each column includes its own value range
# use subset to normalize columns using z-score 
normalized_data = (RA_numeric-RA_numeric.mean())/RA_numeric.std()
normalized_data.head()

#use normalized_data to calculate PCA

# summarize categorical value from original data set
race_count = RA["race"].value_counts().to_frame()
major_count = RA["major"].value_counts().to_frame()
race_count
major_count


```

```{r}

#hypothesis 1: higher gpa = higher score in evaluation
t.test(df$GPA, df$scoreMean)

#make subset without categorical values
drops <- c("race", "major")
df_numeric <- df[, !names(df) %in% drops]


# PCA without normalization (what NOT to do)
RA_pca <- prcomp(df_numeric)
summary(RA_pca)

# Plot PC1 vs PC2
plot(RA_pca$x[,1], RA_pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(RA_pca$x[,1], RA_pca$x[,2], colnames(x))

```
 
 